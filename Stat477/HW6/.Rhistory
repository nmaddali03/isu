##Problem 1
data_bush <- read.csv("Bushapproval.csv")
str(data_bush)
##part a - contingency table
contingency_table <- table(data_bush$First, data_bush$Second)
contingency_table
prop_first <- contingency_table["Yes", "Yes"] / sum(contingency_table["Yes", ])
## part b
## proportion of approval for First time period
prop_approval_first <- sum(contingency_table[1, 1]) / sum(contingency_table[, 1])
## proportion of approval for Second time period
prop_approval_second <- sum(contingency_table[2, 2]) / sum(contingency_table[, 2])
prop_approval_first
prop_approval_second
library(irr)
##Required Functions
mcnemar.ci<- function(table, conf.level = 0.95){
alpha<- 1 - conf.level
z<- qnorm(1 - alpha/2)
n<- sum(table)
y1.<- margin.table(table, 1)[1]
y.1<- margin.table(table, 2)[1]
diff12<- table[1,2]-table[2,1]
add12<- table[1,2]+table[2,1]
se<- sqrt(add12 - diff12^2/n)/n
lowerci<- y1./n - y.1/n - z*se
upperci<- y1./n - y.1/n + z*se
cat("Confidence Interval = ", lowerci, upperci, "\n")
}
##part d - McNemar's test
mcnemar.test(contingency_table, correct = F)
##part e - 95% confidence interval
mcnemar.ci(contingency_table, conf.level = 0.95)
##Problem 2
data_movies <- read.csv("AttheMovies.csv")
str(data_movies)
##part a - contingency table
contingency_table <- table(data_movies$Siskel, data_movies$Ebert)
contingency_table
## part b
## distribution of reviews for Siskel
siskel_distribution <- prop.table(contingency_table, margin = 1)[, "thumbs up"]
##part b
## distribution of reviews for Siskel
siskel_distribution <- prop.table(rowSums(contingency_table))
## distribution of reviews for Ebert
ebert_distribution <- prop.table(colSums(contingency_table))
siskel_distribution
ebert_distribution
##part c - Extension of McNemar's Test
stuart.maxwell.mh(contingency_table)
## part d - Proportion of movies where reviews matched
matched_reviews_count <- sum(diag(contingency_table))  # Sum of counts where reviews matched
total_movies <- sum(contingency_table)  # Total number of movies
proportion_matched <- matched_reviews_count / total_movies
proportion_matched
##part e - Cohen's kappa
kappa2(data_movies)
##part f - weighted Cohen's kappa
kappa2(data_movies, weight = c("squared"))
##Problem 3
data_scores <- read.csv("Scores.csv")
str(data_scores)
##Part a - contingency table
contingency_table <- table(data_scores$Person, data_scores$Computer)
contingency_table
## Part b - Proportion of scores that matched
matched_scores_count <- sum(diag(contingency_table))  # Sum of counts where scores matched
total_responses <- sum(contingency_table)  # Total number of responses
proportion_matched <- matched_scores_count / total_responses
proportion_matched
##part c - Cohen's kappa
kappa2(data_scores)
##part d - weighted Cohen's kappa
kappa2(data_scores, weight = c("squared"))
library(readr)
library(sf)
library(tigris)
library(leaflet)
library(ggplot2)
library(dplyr)
library(randomForest)
# Read data
cfs <- read_rds("C:/Users/neham/Desktop/DS401/DS 401 Spring 2024/Source Data/CGC_CFS_2018-2023.rds")
# Filter out data from 2023
cfs <- cfs %>%
filter(cfs_year < 2023)
# create a weekday column to differentiate between weekday and weekend
cfs <- cfs %>%
mutate(weekdays = ifelse(cfs_weekday %in% 2:6, "Weekday", "Weekend"))
# aggregate the data
# predicting the number of calls in each hour
hourly_calls <- cfs %>%
group_by(cfs_year, cfs_month, cfs_weekday, cfs_hour) %>%
summarise(total_calls = n())
# Split data into training and testing sets
set.seed(123)  # for reproducibility
train_index <- sample(1:nrow(hourly_calls), 0.8 * nrow(hourly_calls))
train_data <- hourly_calls[train_index, ]
test_data <- hourly_calls[-train_index, ]
# Build the random forest model
rf_model <- randomForest(total_calls ~ cfs_year + cfs_month + cfs_weekday + cfs_hour, data = train_data)
rf_model
# Predict on the test set
predictions <- predict(rf_model, newdata = test_data)
predictions
# Combine actual and predicted values into a dataframe
comparison_data <- data.frame(Actual = test_data$total_calls, Predicted = predictions)
# Plot actual versus predicted values
ggplot(comparison_data, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a line of equality
labs(x = "Actual Number of Calls", y = "Predicted Number of Calls", title = "Actual vs Predicted Number of Calls")
# Evaluate Test MSE
test_predictions <- predict(rf_model, newdata = test_data)
test_mse <- mean((test_predictions - test_data$total_calls)^2)
print(paste("Test MSE:", test_mse))
# Feature Importance
importance_rf <- importance(rf_model)
print(importance_rf)
# Plot Feature Importance
varImpPlot(rf_model)

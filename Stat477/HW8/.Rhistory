##Problem 1 - Fit Model with GPA and MCAT
med<- read.csv(file.choose(), header=T)
str(med)
library(ggplot2)
library(pROC)
library(ResourceSelection)
##Required Functions
glm.prob.ci<- function(model, newdata = NULL, conf.level = 0.95){
alpha2.level<- conf.level + (1 - conf.level)/2
z_alpha2<- qnorm(alpha2.level, 0, 1)
if (is.null(newdata)=="TRUE") {
model.logodds<- predict.glm(model, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
model$data<- cbind(model$data, model.probs.lci, model.probs.uci)
model$data
} else {
model.logodds<- predict.glm(model, newdata = newdata, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
probs.ci<- cbind(model.probs.lci, model.probs.uci)
colnames(probs.ci)<- c(as.character(100*(1-alpha2.level)),
as.character(100*alpha2.level))
list(probs.ci)
}
}
confusion.glm <- function(model, cutoff = 0.5) {
predicted <- ifelse(predict(model, type='response') > cutoff,
1, 0)
observed<- model$y
confusion  <- table(observed, predicted)
agreement<- (confusion[1,1]+confusion[2,2])/sum(confusion)
specificity<- confusion[1,1]/rowSums(confusion)[1]
sensitivity<- confusion[2,2]/rowSums(confusion)[2]
list("Confusion Table" = confusion,
"Agreement" = agreement,
"Sensitivity" = sensitivity,
"Specificity" = specificity)
}
McFR2<- function(model) {
G2<- model$deviance
G2null<- model$null.deviance
McFR2<- 1 - G2/G2null
McFR2
}
##Part b - Prediction
model <- glm(Acceptance ~ MCAT + GPA, data = med, family = binomial)
new_data <- data.frame(MCAT = 38, GPA = 3.54)
probability_prediction <- glm.prob.ci(model, newdata = new_data)
print(probability_prediction)
##Part c - Confidence interval for probability
glm.prob.ci(model, newdata = new_data, conf.level = 0.95)
model
##Part d - test for overall significance
model0<- glm(Acceptance ~ 1, data = med,
family = binomial)
anova(model0, model, test = "Chisq")
## Perform Wald test for GPA significance
wald_test_gpa <- summary(model)$coefficients["GPA", "Pr(>|z|)"]
## Perform Wald test for MCAT significance
wald_test_mcat <- summary(model)$coefficients["MCAT", "Pr(>|z|)"]
## Print the results
print(paste("Wald test for GPA significance (p-value):", wald_test_gpa))
print(paste("Wald test for MCAT significance (p-value):", wald_test_mcat))
wald_test_GPA <- summary(model)$coefficients["GPA", "Pr(>|z|)"]
wald_test_GPA
gpa_coefficients <- summary(model)$coefficients["GPA", ]
gpa_test_statistic <- gpa_coefficients["z"]
gpa_p_value <- gpa_coefficients["Pr(>|z|)"]
gpa_test_statistic
gpa_p_value
## Fit logistic regression model
model <- glm(Acceptance ~ MCAT + GPA, data = med, family = binomial)
## Test for GPA variable (Wald Test)
gpa_coefficients <- summary(model)$coefficients["GPA", ]
gpa_test_statistic <- gpa_coefficients["z"]
gpa_p_value <- gpa_coefficients["Pr(>|z|)"]
## Test for MCAT variable (Wald Test)
mcat_coefficients <- summary(model)$coefficients["MCAT", ]
mcat_test_statistic <- mcat_coefficients["z"]
mcat_p_value <- mcat_coefficients["Pr(>|z|)"]
## Display results
cat("Test for GPA variable (using Wald Test):\n")
cat("Null Hypothesis: The coefficient for GPA is equal to zero.\n")
cat("Alternative Hypothesis: The coefficient for GPA is not equal to zero.\n")
cat("Test statistic:", gpa_test_statistic, "\n")
cat("P-value:", gpa_p_value, "\n")
cat("Conclusion: [Your interpretation based on the p-value and significance level.]\n\n")
cat("Test for MCAT variable (using Wald Test):\n")
cat("Null Hypothesis: The coefficient for MCAT is equal to zero.\n")
cat("Alternative Hypothesis: The coefficient for MCAT is not equal to zero.\n")
cat("Test statistic:", mcat_test_statistic, "\n")
cat("P-value:", mcat_p_value, "\n")
cat("Conclusion: [Your interpretation based on the p-value and significance level.]\n")
##Required Libraries
library(ggplot2)
library(pROC)
library(ResourceSelection)
##Required Functions
glm.prob.ci<- function(model, newdata = NULL, conf.level = 0.95){
alpha2.level<- conf.level + (1 - conf.level)/2
z_alpha2<- qnorm(alpha2.level, 0, 1)
if (is.null(newdata)=="TRUE") {
model.logodds<- predict.glm(model, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
model$data<- cbind(model$data, model.probs.lci, model.probs.uci)
model$data
} else {
model.logodds<- predict.glm(model, newdata = newdata, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
probs.ci<- cbind(model.probs.lci, model.probs.uci)
colnames(probs.ci)<- c(as.character(100*(1-alpha2.level)),
as.character(100*alpha2.level))
list(probs.ci)
}
}
confusion.glm <- function(model, cutoff = 0.5) {
predicted <- ifelse(predict(model, type='response') > cutoff,
1, 0)
observed<- model$y
confusion  <- table(observed, predicted)
agreement<- (confusion[1,1]+confusion[2,2])/sum(confusion)
specificity<- confusion[1,1]/rowSums(confusion)[1]
sensitivity<- confusion[2,2]/rowSums(confusion)[2]
list("Confusion Table" = confusion,
"Agreement" = agreement,
"Sensitivity" = sensitivity,
"Specificity" = specificity)
}
McFR2<- function(model) {
G2<- model$deviance
G2null<- model$null.deviance
McFR2<- 1 - G2/G2null
McFR2
}
##Problem 1
spiderdata<- read.csv(file.choose(), header=T)
##Calculate sample proportion for cannibalism variable
cannibalism_count <- sum(spiderdata$Cannibalism == "Yes")
proportion_cannibalism <- cannibalism_count / nrow(spiderdata)
proportion_cannibalism
##Problem 2
##Fit the logistic regression model
# Convert "Cannibalism" variable to 0 and 1
spiderdata$Cannibalism <- as.factor(ifelse(spiderdata$Cannibalism == "Yes", 1, 0))
logit_model <- glm(Cannibalism ~ Size.Difference..Female...Male., data = spiderdata, family = binomial)
summary(logit_model)
##Use function hoslem.test to calculate test statistic
##and p-value for Hosmer-Lemeshow test
hoslem_result <- hoslem.test(spiderdata$Cannibalism, logit_model$fitted.values, g = 5)
hoslem_result
##Fit the logistic regression model
# Convert "Cannibalism" variable to 0 and 1
spiderdata$Cannibalism <- factor(spiderdata$Cannibalism, levels = c("No", "Yes"))
logit_model <- glm(Cannibalism ~ Size.Difference..Female...Male., data = spiderdata, family = binomial(link=logit))
##Required Libraries
library(ggplot2)
library(pROC)
library(ResourceSelection)
##Required Functions
glm.prob.ci<- function(model, newdata = NULL, conf.level = 0.95){
alpha2.level<- conf.level + (1 - conf.level)/2
z_alpha2<- qnorm(alpha2.level, 0, 1)
if (is.null(newdata)=="TRUE") {
model.logodds<- predict.glm(model, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
model$data<- cbind(model$data, model.probs.lci, model.probs.uci)
model$data
} else {
model.logodds<- predict.glm(model, newdata = newdata, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
probs.ci<- cbind(model.probs.lci, model.probs.uci)
colnames(probs.ci)<- c(as.character(100*(1-alpha2.level)),
as.character(100*alpha2.level))
list(probs.ci)
}
}
confusion.glm <- function(model, cutoff = 0.5) {
predicted <- ifelse(predict(model, type='response') > cutoff,
1, 0)
observed<- model$y
confusion  <- table(observed, predicted)
agreement<- (confusion[1,1]+confusion[2,2])/sum(confusion)
specificity<- confusion[1,1]/rowSums(confusion)[1]
sensitivity<- confusion[2,2]/rowSums(confusion)[2]
list("Confusion Table" = confusion,
"Agreement" = agreement,
"Sensitivity" = sensitivity,
"Specificity" = specificity)
}
McFR2<- function(model) {
G2<- model$deviance
G2null<- model$null.deviance
McFR2<- 1 - G2/G2null
McFR2
}
##Problem 1
spiderdata<- read.csv(file.choose(), header=T)
##Calculate sample proportion for cannibalism variable
cannibalism_count <- sum(spiderdata$Cannibalism == "Yes")
proportion_cannibalism <- cannibalism_count / nrow(spiderdata)
proportion_cannibalism
##Fit the logistic regression model
# Convert "Cannibalism" variable to 0 and 1
spiderdata$Cannibalism <- factor(spiderdata$Cannibalism, levels = c("No","Yes"))
# spiderdata$Cannibalism <- as.factor(ifelse(spiderdata$Cannibalism == "Yes", 1, 0))
logit_model <- glm(Cannibalism ~ Size.Difference..Female...Male., data = spiderdata, family = binomial(link=logit))
summary(logit_model)
##Problem 4
##Calculate exp(slope)
##Calculate exp(intercept)
logit_model$coefficients
##Problem 5
# Define the logistic regression equation
logistic_eq <- function(size_difference) {
probability <- 1 / (1 + exp(-( -3.0890 + 3.0693 * size_difference)))
return(probability)
}
##Calculate predicted probability for difference = -0.2mm
prob_minus_0_2mm <- logistic_eq(-0.2)
prob_minus_0_2mm
# Calculate predicted probability for difference = 0.4mm
prob_0_4mm <- logistic_eq(0.4)
prob_0_4mm
##Calculate confidence interval for probability for difference = 0mm
newdiff = data.frame(Size.Difference..Female...Male. = 0)
glm.prob.ci(logit_model, newdata = newdiff, conf.level = 0.95)
##Calculate confidence interval for probability for difference = 0.8mm
newdiff = data.frame(Size.Difference..Female...Male. = 0.8)
glm.prob.ci(logit_model, newdata = newdiff, conf.level = 0.95)
##Wald test information is in summary(model)
summary(logit_model)
##Calculate Likelihood Ratio Test statistic and p-value
anova(logit_model, test = "Chisq")
##Problem 8
##Use function McFR2 to calculate McFadden's R^2
McFR2(logit_model)
##Problem 9
##Use function hoslem.test to calculate test statistic
##and p-value for Hosmer-Lemeshow test
hoslem_result <- hoslem.test(spiderdata$Cannibalism, logit_model$fitted.values, g = 5)
hoslem_result
##Homework 8 Template
##Required Libraries
library(ggplot2)
library(pROC)
library(ResourceSelection)
##Required Functions
glm.prob.ci<- function(model, newdata = NULL, conf.level = 0.95){
alpha2.level<- conf.level + (1 - conf.level)/2
z_alpha2<- qnorm(alpha2.level, 0, 1)
if (is.null(newdata)=="TRUE") {
model.logodds<- predict.glm(model, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
model$data<- cbind(model$data, model.probs.lci, model.probs.uci)
model$data
} else {
model.logodds<- predict.glm(model, newdata = newdata, se.fit = T)
model.logodds.lci<- model.logodds$fit - z_alpha2*model.logodds$se.fit
model.logodds.uci<- model.logodds$fit + z_alpha2*model.logodds$se.fit
model.probs.lci<- exp(model.logodds.lci)/(1 + exp(model.logodds.lci))
model.probs.uci<- exp(model.logodds.uci)/(1 + exp(model.logodds.uci))
probs.ci<- cbind(model.probs.lci, model.probs.uci)
colnames(probs.ci)<- c(as.character(100*(1-alpha2.level)),
as.character(100*alpha2.level))
list(probs.ci)
}
}
confusion.glm <- function(model, cutoff = 0.5) {
predicted <- ifelse(predict(model, type='response') > cutoff,
1, 0)
observed<- model$y
confusion  <- table(observed, predicted)
agreement<- (confusion[1,1]+confusion[2,2])/sum(confusion)
specificity<- confusion[1,1]/rowSums(confusion)[1]
sensitivity<- confusion[2,2]/rowSums(confusion)[2]
list("Confusion Table" = confusion,
"Agreement" = agreement,
"Sensitivity" = sensitivity,
"Specificity" = specificity)
}
McFR2<- function(model) {
G2<- model$deviance
G2null<- model$null.deviance
McFR2<- 1 - G2/G2null
McFR2
}
##Problem 1 - Fit Model with GPA and MCAT
med<- read.csv(file.choose(), header=T)
##Part b - Prediction
model <- glm(Acceptance ~ MCAT + GPA, data = med, family = binomial)
model
##Part c - Confidence interval for probability
new_data <- data.frame(MCAT = 38, GPA = 3.54)
glm.prob.ci(model, newdata = new_data, conf.level = 0.95)
##Part d - test for overall significance
model0<- glm(Acceptance ~ 1, data = med,
family = binomial)
anova(model0, model, test = "Chisq")
##Part e - test for GPA and MCAT significance using Wald test
# Coefficient estimate for GPA
coef_GPA <- coef(model)["GPA"]
# Standard error for GPA coefficient
se_GPA <- summary(model)$coefficients["GPA", "Std. Error"]
# Wald statistic
wald_GPA <- (coef_GPA / se_GPA)^2
# Degrees of freedom for chi-square distribution (1 for single predictor)
df <- 1
# P-value
p_value_GPA <- 1 - pchisq(wald_GPA, df)
# Print results
cat("Wald Statistic (GPA):", wald_GPA, "\n")
cat("P-value (GPA):", p_value_GPA, "\n")
# Conclusion
if (p_value_GPA < 0.05) {
cat("Conclusion: Reject the null hypothesis. GPA is a significant predictor of Acceptance.\n")
} else {
cat("Conclusion: Fail to reject the null hypothesis. GPA is not a significant predictor of Acceptance.\n")
}
##part a
model2 <- glm(Acceptance ~ MCAT + GPA + Sex, data = med, family = binomial)
model2
summary(model2)
##part b
##confidence interval for slope
exp(confint(model2)[4,])
summary(model)
model_interaction<- glm(Acceptance ~ MCAT + GPA + MCAT:GPA,
data = med,
family = binomial)
summary(model_interaction)
##Part c - Confidence interval for probability
new_data <- data.frame(MCAT = 38, GPA = 3.54)
glm.prob.ci(model_interaction, newdata = new_data, conf.level = 0.95)
##For Final Model, find:
full_model <- glm(Acceptance ~ MCAT + GPA + Sex + Apps, data = med, family = binomial)
summary(full_model)
modelstep1<- step(full_model)
dim(med)
str(med)
modelstep2<- step(full_model, k = log(55))
##McFadden's R-square
McFR2(modelstep1)
##Hosmer-Lemeshow goodness of fit test
hoslem.test(med$Acceptance,
modelstep1$fitted.values, g = 5)
##Confusion Table
confusion.glm(modelstep1)
##Roc Curve analysis
medroc<- roc(med$Acceptance ~ modelstep1$fitted.values)
ggroc(medroc)+
theme_bw()+
theme(axis.title.y = element_text(size = rel(1.4)))+
theme(axis.title.x = element_text(size = rel(1.4)))+
theme(axis.text.x = element_text(size = rel(1.2)))+
theme(axis.text.y = element_text(size = rel(1.2)))+
theme(plot.title = element_text(hjust=0.5, size = rel(1.6)))+
geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1),
linetype="dashed")+
labs(x = "Specificity",
y = "Sensitivity",
title = "ROC Curve for 'Best' Med Acceptance Model")
auc(medroc)

fp_lda_adjusted
#part d
threshold_lda = 0.1  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
fp_lda_adjusted = lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
fp_lda_adjusted
#part d
threshold_lda = 0.3  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
fp_lda_adjusted = lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
fp_lda_adjusted
#part d
threshold_lda = 0.09  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
fp_lda_adjusted = lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
fp_lda_adjusted
#part d
threshold_lda = 0.05  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
#part d
threshold_lda = 0.6  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
#part d
threshold_lda = 0.8  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
#part d
threshold_lda = 0.1  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
#part d
threshold_lda = 0.01  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
#part d
threshold_lda = 0.02  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
#part d
threshold_lda = 0.03  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
################## 5d. ####################
library(MASS)
##################################
## Problem 5: Email Spam Part 2 ##
##################################
################## 5b. ####################
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
################## 5d. ####################
library(MASS)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
##################################
## Problem 5: Email Spam Part 2 ##
##################################
################## 5b. ####################
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
table(spam['V58'])
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model = glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred = prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 5c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 5d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
ROCRperf_lda = performance(ROCRpred_lda, "tpr", "fpr")
plot(ROCRperf_lda, colorize = TRUE, print.cutoffs.at = seq(0, 1, by = 0.05), text.adj = c(-0.2, 1.7))
#part b
library(pROC)  # Load the pROC package for ROC analysis
#part c
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.5] = 1
lda_confusion = table(lda_preds, test$V58)
fp_lda = lda_confusion[2, 1] / sum(lda_confusion[, 1])  # False positive rate
fn_lda = lda_confusion[1, 2] / sum(lda_confusion[, 2])  # False negative rate
fp_lda
npk
np_lda
fn_lda
#part d
threshold_lda = 0.03  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
#part d
threshold_lda = 0.3  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
table(spam['V58'])
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model = glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred = prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 5d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
ROCRperf_lda = performance(ROCRpred_lda, "tpr", "fpr")
plot(ROCRperf_lda, colorize = TRUE, print.cutoffs.at = seq(0, 1, by = 0.05), text.adj = c(-0.2, 1.7))
#part c
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.5] = 1
lda_confusion = table(lda_preds, test$V58)
fp_lda = lda_confusion[2, 1] / sum(lda_confusion[, 1])  # False positive rate
fn_lda = lda_confusion[1, 2] / sum(lda_confusion[, 2])  # False negative rate
#part d
threshold_lda = 0.15  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
#part d
threshold_lda = 0.2  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
table(spam['V58'])
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model = glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred = prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 5c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 5d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
ROCRperf_lda = performance(ROCRpred_lda, "tpr", "fpr")
plot(ROCRperf_lda, colorize = TRUE, print.cutoffs.at = seq(0, 1, by = 0.05), text.adj = c(-0.2, 1.7))
#part c
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.5] = 1
lda_confusion = table(lda_preds, test$V58)
fp_lda = lda_confusion[2, 1] / sum(lda_confusion[, 1])  # False positive rate
fn_lda = lda_confusion[1, 2] / sum(lda_confusion[, 2])  # False negative rate
#part d
threshold_lda = 0.2  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
table(spam['V58'])
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model = glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred = prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 5c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 5d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
ROCRperf_lda = performance(ROCRpred_lda, "tpr", "fpr")
plot(ROCRperf_lda, colorize = TRUE, print.cutoffs.at = seq(0, 1, by = 0.05), text.adj = c(-0.2, 1.7))
#part c
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.5] = 1
lda_confusion = table(lda_preds, test$V58)
fp_lda = lda_confusion[2, 1] / sum(lda_confusion[, 1])  # False positive rate
fn_lda = lda_confusion[1, 2] / sum(lda_confusion[, 2])  # False negative rate
#part d
threshold_lda = 0.45  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
table(spam['V58'])
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model = glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred = prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 5c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 5d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
ROCRperf_lda = performance(ROCRpred_lda, "tpr", "fpr")
plot(ROCRperf_lda, colorize = TRUE, print.cutoffs.at = seq(0, 1, by = 0.05), text.adj = c(-0.2, 1.7))
#part c
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.5] = 1
lda_confusion = table(lda_preds, test$V58)
fp_lda = lda_confusion[2, 1] / sum(lda_confusion[, 1])  # False positive rate
fn_lda = lda_confusion[1, 2] / sum(lda_confusion[, 2])  # False negative rate
#part d
threshold_lda = 0.55  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
table(spam['V58'])
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model = glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred = prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 5c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 5d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
ROCRperf_lda = performance(ROCRpred_lda, "tpr", "fpr")
plot(ROCRperf_lda, colorize = TRUE, print.cutoffs.at = seq(0, 1, by = 0.05), text.adj = c(-0.2, 1.7))
#part c
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.5] = 1
lda_confusion = table(lda_preds, test$V58)
fp_lda = lda_confusion[2, 1] / sum(lda_confusion[, 1])  # False positive rate
fn_lda = lda_confusion[1, 2] / sum(lda_confusion[, 2])  # False negative rate
#part d
threshold_lda = 0.57  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
library(caret)
spam = read.csv('/Users/neham/Desktop/DS303/HW/spambase.data',header=FALSE)
table(spam['V58'])
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model = glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred = prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 5c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 5d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
################## 5d. ####################
library(MASS)
lda_model = lda(V58 ~ ., data = train)
lda_probs = predict(lda_model, newdata = test, type = "response")$posterior[, "1"]
# part b
ROCRpred_lda = prediction(lda_probs, test$V58)
ROCRperf_lda = performance(ROCRpred_lda, "tpr", "fpr")
plot(ROCRperf_lda, colorize = TRUE, print.cutoffs.at = seq(0, 1, by = 0.05), text.adj = c(-0.2, 1.7))
#part c
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.5] = 1
lda_confusion = table(lda_preds, test$V58)
fp_lda = lda_confusion[2, 1] / sum(lda_confusion[, 1])  # False positive rate
fn_lda = lda_confusion[1, 2] / sum(lda_confusion[, 2])  # False negative rate
#part d
threshold_lda = 0.57  # Adjust this threshold as needed
lda_preds[lda_probs > threshold_lda] = 1
lda_confusion_adjusted = table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
fp_lda
#part d
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.6] = 1
table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
lda_preds[lda_probs > 0.7] = 1
table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
lda_preds[lda_probs > 0.2] = 1
table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
lda_preds[lda_probs > 0.25] = 1
table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
lda_preds[lda_probs > 0.19] = 1
table(lda_preds, test$V58)
lda_confusion_adjusted[2, 1] / sum(lda_confusion_adjusted[, 1])  # Adjusted false positive rate
lda_confusion_adjusted[1, 2] / sum(lda_confusion_adjusted[, 2])  # Adjusted false negative rate
#part d
lda_preds = rep(0, nrow(test))
lda_preds[lda_probs > 0.19] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 66 / (66+1190)
fp_lda_adjusted
lda_preds[lda_probs > 0.17] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 60 / (60+1169)
fp_lda_adjusted
lda_preds[lda_probs > 0.16] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 57 / (57+1157)
fp_lda_adjusted
lda_preds[lda_probs > 0.15] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 53 / (53+1138)
fp_lda_adjusted
lda_preds[lda_probs > 0.12] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 42 / (42+1068)
fp_lda_adjusted
lda_preds[lda_probs > 0.1] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 35 / (35+1005)
fp_lda_adjusted
lda_preds[lda_probs > 0.09] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 32 / (32+969)
fp_lda_adjusted
lda_preds[lda_probs > 0.08] = 1
table(lda_preds, test$V58)
fp_lda_adjusted = 25 / (25+918)
fp_lda_adjusted
fn_lda_adjusted = 497 / (497+861)
fn_lda_adjusted
# Load necessary libraries
library(MASS)  # For QDA
library(e1071)  # For Naive Bayes
library(class)  # For KNN
library(caret)  # For cross-validation
# Standardize predictors for KNN
standardized_train <- scale(train[, -ncol(train)])
standardized_test <- scale(test[, -ncol(test)])
# QDA
qda_model <- qda(V58 ~ ., data = train)
library(MASS)
qda_model = qda(V58 ~ ., data = train)

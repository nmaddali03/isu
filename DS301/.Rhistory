################## 3d. ####################
preds[probs > 0.2] = 1
table(preds, test$V58)
################## 3a. ####################
library(caret)
spam = read.csv('/Users/neham/Desktop/DS301/spambase.data',header=FALSE)
table(spam['V58'])
################## 3b. ####################
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model <- glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred <- prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 3c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
fp
fn
################## 3d. ####################
preds[probs > 0.2] = 1
table(preds, test$V58)
fp = 25 / (25+1229)
fp
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fp
fn = 243 / (243+870)
fn
preds[probs > 0.10] = 1
table(preds, test$V58)
preds[probs > 0.120] = 1
table(preds, test$V58)
preds[probs > 0.13] = 1
table(preds, test$V58)
preds[probs > 0.05] = 1
table(preds, test$V58)
preds[probs > 0.25] = 1
table(preds, test$V58)
preds[probs > 0.20] = 1
table(preds, test$V58)
preds[probs > 0.1] = 1
table(preds, test$V58)
################## 3a. ####################
library(caret)
spam = read.csv('/Users/neham/Desktop/DS301/spambase.data',header=FALSE)
table(spam['V58'])
################## 3b. ####################
set.seed(1)
train_spam = sample(1:nrow(spam),nrow(spam)/2)
train = spam[train_spam,]
test = spam[-train_spam,]
table(train['V58'])
table(test['V58'])
logit_model <- glm(V58~., data=test, family=binomial)
summary(logit_model)
probs = predict(logit_model, type="response")
head(probs,10)
preds = rep(0, nrow(test))
preds[probs > .5] = 1
table(preds, test$V58)
1-mean(preds == test$V58)
library(ROCR)
ROCRpred <- prediction(probs,test$V58)
plot(performance(ROCRpred,'tpr','fpr'),colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.05), text.adj=c(-0.2,1.7))
################## 3c. ####################
table(preds, test$V58)
fp = 89 / (89+1351)
fn = 64 / (64+797)
################## 3d. ####################
preds[probs > 0.15] = 1
table(preds, test$V58)
fp = 16 / (16+1172)
fn = 243 / (243+870)
fp
fn
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images-idx3-ubyte')
test <<- load_image_file('t10k-images-idx3-ubyte')
train$y <<- load_label_file('train-labels-idx1-ubyte')
test$y <<- load_label_file('t10k-labels-idx1-ubyte')
return(
list(
train = train,
test = test
)
)
}
################## 1a. ####################
mnist = load_mnist()
getwd()
################## 1a. ####################
setwd("Users/neham/Desktop/DS301")
getwd()
################## 1a. ####################
setwd("Users/neham/Desktop/DS301")
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
mnist
dim(mnist)
str(mnist)
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
k1 = knn(train$x[index.train,], test$x[index.test,],train$y[index.train], k=1)
head(k1)
table(k1,test$y[index.test,])
table(k1,test$y)
table(k1,index.test)
mean(test$x[index.test,]!=k1)
k5 = knn(train$x[index.train,], test$x[index.test,],train$y[index.train], k=5)
mean(test$x[index.test,]!=k5)
k7 = knn(train$x[index.train,], test$x[index.test,],train$y[index.train], k=7)
mean(test$x[index.test,]!=k7)
k9 = knn(train$x[index.train,], test$x[index.test,],train$y[index.train], k=9)
mean(test$x[index.test,]!=k9)
mean(index.test!=k1)
library(ISLR2)
#install.packages('class')
library(class)
head(Caravan)
# That said: does scale of the variables matter?
var(Caravan[,1])
var(Caravan[,2])
standardized.X = scale(Caravan[,-86])
var(standardized.X[,1])
var(standardized.X[,2])
test = 1:1000
train.X = standardized.X[-test,]
test.X = standardized.X[test,]
train.Y = Caravan$Purchase[-test]
test.Y = Caravan$Purchase[test]
set.seed(1)
knn.pred = knn(train.X,test.X,train.Y,k=1)
head(knn.pred)
table(knn.pred,test.Y)
mean(test.Y!=knn.pred)
table(test.Y)
mean(test.Y=="Yes") # only 6% of customers purchased insurance. We could reduce our misclassification rate to 6%
library(caret)
Caravan2 = Caravan[-test,]
standardized.X2 = scale(Caravan2[,-86])
flds <- createFolds(Caravan2$Purchase, k = 5, list = TRUE, returnTrain = FALSE)
names(flds)
K= c(1,3,5) # nearest neighbor values
cv_error = matrix(NA, 5, 3)
for(j in 1:3){
k = K[j]
for(i in 1:5){
test_index = flds[[i]]
testX = standardized.X2[test_index,]
trainX = standardized.X2[-test_index,]
trainY = Caravan2$Purchase[-test_index]
testY = Caravan2$Purchase[test_index]
knn.pred = knn(trainX,testX,trainY,k=k)
cv_error[i,j] = mean(testY!=knn.pred)
}
}
apply(cv_error,2,mean)
knn.pred = knn(train.X,test.X,train.Y,k=5)
mean(test.Y!=knn.pred)
k5 = knn(train$x[index.train,], test$x[index.test,],train$y[index.train], k=5)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
mnist = load_mnist()
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
k5 = knn(train$x[index.train,], test$x[index.test,],train$y[index.train], k=5)
table(k5, test$y[index.test,])
table(k5,test$y)
mean(test$Y[index.test,]!=knn.pred)
mean(test$Y[index.test,]!=k5)
mean(test$y[index.test,]!=k5)
k5 = knn(train$x[index.train,], test$x[index.test], train$y[index.train,], k=5)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
k5 = knn(train$x[index.train,], test$x[index.test], train$y[index.train,], k=5)
k5 = knn(train$x[index.train,], test$x[index.test,], train$y[index.train], k=5)
table(k5, index.test$y)
table(k5, test$y[index.test])
mean(test$y[index.test]!=k5)
k7 = knn(train$x[index.train,], test$x[index.test,], train$y[index.train], k=7)
table(k7, test$y[index.test])
mean(test$y[index.test]!=k7)
k9 = knn(train$x[index.train,], test$x[index.test,], train$y[index.train], k=9)
table(k5, test$y[index.test])
mean(test$y[index.test]!=k9)
k1 = knn(train$x[index.train,], test$x[index.test,], train$y[index.train], k=1)
table(k1, test$y[index.test])
mean(test$y[index.test]!=k1)
################## 2a. ####################
set.seed(1)
x1 = rnorm(1000,0,0.9) # create 3 predictors
x2 = rnorm(1000,1,1)
x3 = rnorm(1000,0,2)
B0 = 1
B1 = 2
B2 = 3
B3 = 2
pr = (exp(B0+B1*x1+B2*x2+B3*x3))/(1+exp(B0+B1*x1+B2*x2+B3*x3))
y = rbinom(1000,1,pr)
df = data.frame(y=y,x1=x1,x2=x2, x3=x3)
################## 2b. ####################
set.seed(1)
train = sample(1:nrow(df),nrow(df)/2, replace=FALSE)
test = (-train)
glm.fit = glm(y~x1+x2+x3, data=df,subset=train,family='binomial')
summary(glm.fit)
glm.prob = predict(glm.fit,df[test,],type='response')
glm.pred = rep(0,length(test))
glm.pred[glm.prob >0.5] =1
table(glm.pred,df[test,]$y) #rows are predicted, # columns are true
1-mean(glm.pred == df[test,]$y)
################## 2c. ####################
library(MASS)
lda.fit = lda(y~x1+x2+x3, data=df, subset=train)
summary(lda.fit)
lda.pred = predict(lda.fit,df[test,])
table(lda.pred$class,df[test,]$y)
mean(lda.pred$class!=df[test,]$y)
################## 2d. ####################
library(caret)
library(class)
var(df[,1])
var(df[,2])
standardized.X = scale(df[,-1])
var(standardized.X[,1])
var(standardized.X[,2])
train.X = standardized.X[-test,]
test.X = standardized.X[test,]
train.Y = df$y[-test]
test.Y = df$y[test]
flds <- createFolds(train.Y, k=5, list=TRUE, returnTrain=FALSE)
K = c(1,3,5)
cv_error = matrix(NA,5,3)
for(j in 1:3){
k=K[j]
for(i in 1:5){
test_index = flds[[i]]
testX = train.X[test_index,]
trainX = train.X[-test_index,]
trainY = train.Y[-test_index]
trainX = train.Y[test_index]
knn.pred = knn(testX, trainX, trainY, k=k)
cv_error[i,j] = mean(testY!=knn.pred)
}
}
apply(cv_error, 2, mean)
for(j in 1:3){
k=K[j]
for(i in 1:5){
test_index = flds[[i]]
testX = train.X[test_index,]
trainX = train.X[-test_index,]
trainY = train.Y[-test_index]
trainX = train.Y[test_index]
knn.pred = knn(testX, trainX, trainY, k=k)
cv_error[i,j] = mean(testY!=knn.pred)
}
}
apply(cv_error, 2, mean)
knn.pred = knn(train.X, test.X, train.Y, k=5)
table(knn.pred, test.Y)
mean(test.Y!=knn.pred)
knn.pred = knn(train.X, test.X, train.Y, k=3)
table(knn.pred, test.Y)
mean(test.Y!=knn.pred)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
################## 1b. ####################
library(MASS)
lda.fit = lda(y~., data=mnist, subset=train)
lda.fit = lda(y~., data=mnist, subset=index.train)
var(train$x[,1])
lda.fit = lda(y~., data=mnist)
summary(lda.fit)
lda.pred = predict(lda.fit,mnist[index.test,])
table(lda.pred$class,mnist[index.test,]$y)
mean(lda.pred$class!=mnist[index.test,]$y)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
var(mnist[,1])
train.X = mnist[-index.test,]
train.X = mnist[index.train,]
train.Y = mnist$y[-index.test]
test.Y = mnist$y[index.test]
train.X = mnist$x[index.train,]
test.X = mnist$x[index.test,]
train.Y = mnist$y[index.train]
test.Y = mnist$y[index.test]
flds <- createFolds(train.Y, k=10, list=TRUE, returnTrain=FALSE)
flds <- createFolds(train.Y, k=10, list=TRUE, returnTrain=FALSE)
flds <- createFolds(train.Y, k=5, list=TRUE, returnTrain=FALSE)
train.X = mnist$x[index.train,]
test.X = mnist$x[index.test,]
train.Y = mnist$y[index.train]
test.Y = mnist$y[index.test]
flds <- createFolds(train.Y, k=5, list=TRUE, returnTrain=FALSE)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
train.X = mnist$x[index.train,]
test.X = mnist$x[index.test,]
train.Y = mnist$y[index.train]
test.Y = mnist$y[index.test]
flds <- createFolds(train.Y, k=5, list=TRUE, returnTrain=FALSE)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
k5 = knn(train$x[index.train,], test$x[index.test,], train$y[index.train], k=5)
table(k5, test$y[index.test])
mean(test$y[index.test]!=k5)
################## 1b. ####################
library(MASS)
lda.fit = lda(y~., data=mnist, subset=index.train)
var(train$x[,1])
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
ls()
library(class)
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
train.X = train$x[index.train,]
test.X = test$x[index.test,]
train.Y = train$y[index.train]
test.Y = test$y[index.test]
flds <- createFolds(train.Y, k=10, list=TRUE, returnTrain=FALSE)
names(flds)
K = c(1,5,7,9)
cv_error = matrix(NA,10,4)
for(j in 1:4){
k=K[j]
for(i in 1:10){
test_index = flds[[i]]
testX = train.X[test_index,]
trainX = train.X[-test_index,]
trainY = train.Y[-test_index]
trainX = train.Y[test_index]
knn.pred = knn(trainX, testX, trainY, k=k)
cv_error[i,j] = mean(testY!=knn.pred)
}
}
apply(cv_error, 2, mean)
knn.pred = knn(train.X, test.X, train.Y, k=5)
table(knn.pred, test.Y)
mean(test.Y!=knn.pred)
k5 = knn(train$x[index.train,], test$x[index.test,], train$y[index.train], k=5)
table(k5, test$y[index.test])
mean(test$y[index.test]!=k5)
k=K[j]
for(i in 1:10){
test_index = flds[[i]]
testX = train.X[test_index,]
trainX = train.X[-test_index,]
trainY = train.Y[-test_index]
trainX = train.Y[test_index]
knn.pred = knn(trainX, testX, trainY, k=k)
cv_error[i,j] = mean(testY!=knn.pred)
}
k=K[j]
for(i in 1:10){
test_index = flds[[i]]
testX = train.X[test_index,]
trainX = train.X[-test_index,]
trainY = train.Y[-test_index]
testY = train.Y[test_index]
knn.pred = knn(trainX, testX, trainY, k=k)
cv_error[i,j] = mean(testY!=knn.pred)
}
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
library(class)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
library(caret)
index.train = sample(1:dim(train$x)[1],3000, replace=FALSE)
index.test = sample(1:dim(test$x)[1],100, replace=FALSE)
train.X = train$x[index.train,]
test.X = test$x[index.test,]
train.Y = train$y[index.train]
test.Y = test$y[index.test]
flds <- createFolds(train.Y, k=10, list=TRUE, returnTrain=FALSE)
names(flds)
K = c(1,5,7,9)
cv_error = matrix(NA,10,4)
for(j in 1:4){
k=K[j]
for(i in 1:10){
test_index = flds[[i]]
testX = train.X[test_index,]
trainX = train.X[-test_index,]
trainY = train.Y[-test_index]
testY = train.Y[test_index]
knn.pred = knn(trainX, testX, trainY, k=k)
cv_error[i,j] = mean(testY!=knn.pred)
}
}
apply(cv_error, 2, mean)
knn.pred = knn(train.X, test.X, train.Y, k=5)
table(knn.pred, test.Y)
mean(test.Y!=knn.pred)
k5 = knn(train$x[index.train,], test$x[index.test,], train$y[index.train], k=5)
table(k5, test$y[index.test])
mean(test$y[index.test]!=k5)
################## 1b. ####################
library(MASS)
df = cbind(train$y, train$x)
lda.fit = lda(train$y~train$x, data=df)
################## 1a. ####################
setwd("/Users/neham/Desktop/DS301")
source("/Users/neham/Desktop/DS301/mnist_load_script.R", echo=TRUE)
mnist = load_mnist()
